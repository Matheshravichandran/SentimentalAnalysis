{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "input = cv2.imread('./elephant.jpeg')\n",
    "cv2.imshow('Hello World', input)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "image = cv2.imread('./Computer-Vision-Tutorial-master/image_examples/elephant.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    " \n",
    "if faces is ():\n",
    "    print(\"The faces is empty\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('FaceDetection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./Computer-Vision-Tutorial-master/image_examples/Modi.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"NO faces please\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h),(127,0,243) , 2)\n",
    "    cv2.imshow(\"Face Classifier and eye Classifier\", img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (255,255,0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./Computer-Vision-Tutorial-master/image_examples/Trump.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"There is no face in the picture.\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(123,123,123),2)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,203),2)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and eye detection from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b561bb61cef0>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b561bb61cef0>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    roi_color =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        print(\"There are no faces\")\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,255), 2)\n",
    "        roi_color = \n",
    "        \n",
    "\n",
    "\n",
    "video_capture = cv2.video_capture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "body_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('./Computer-Vision-Tutorial-master/image_examples/walking.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (253,3,230), 2)\n",
    "        cv2.imshow('Pedestrians', frame)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "car_classifier = cv2.CascadeClassifier('./Computer-Vision-Tutorial-master/Haarcascades/haarcascade_car.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('./Computer-Vision-Tutorial-master/image_examples/cars.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    time.sleep(.05)\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (234,45,24), 2)\n",
    "        cv2.imshow('Car', frame)\n",
    "    \n",
    "    if cv2.waitKey(2) == 13:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Velocity Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2 # opencv library\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get file names of the frames\n",
    "col_frames = os.listdir('frames/')\n",
    "\n",
    "# sort file names\n",
    "col_frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "# empty list to store the frames\n",
    "col_images=[]\n",
    "\n",
    "for i in col_frames:\n",
    "    # read the frames\n",
    "    img = cv2.imread('frames/'+i)\n",
    "    # append the frames to the list\n",
    "    col_images.append(img)\n",
    "\n",
    "# kernel for image dilation\n",
    "kernel = np.ones((4,4),np.uint8)\n",
    "\n",
    "# font style\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# directory to save the ouput frames\n",
    "pathIn = \"contour_frames_3/\"\n",
    "\n",
    "for i in range(len(col_images)-1):\n",
    "    \n",
    "    # frame differencing\n",
    "    grayA = cv2.cvtColor(col_images[i], cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(col_images[i+1], cv2.COLOR_BGR2GRAY)\n",
    "    diff_image = cv2.absdiff(grayB, grayA)\n",
    "    \n",
    "    # image thresholding\n",
    "    ret, thresh = cv2.threshold(diff_image, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # image dilation\n",
    "    dilated = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "    \n",
    "    # find contours\n",
    "    contours, hierarchy = cv2.findContours(dilated.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # shortlist contours appearing in the detection zone\n",
    "    valid_cntrs = []\n",
    "    for cntr in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        if (x <= 200) & (y >= 80) & (cv2.contourArea(cntr) >= 25):\n",
    "            if (y >= 90) & (cv2.contourArea(cntr) < 40):\n",
    "                break\n",
    "            valid_cntrs.append(cntr)\n",
    "            \n",
    "    # add contours to original frames\n",
    "    dmy = col_images[i].copy()\n",
    "    cv2.drawContours(dmy, valid_cntrs, -1, (127,200,0), 2)\n",
    "    \n",
    "    cv2.putText(dmy, \"vehicles detected: \" + str(len(valid_cntrs)), (55, 15), font, 0.6, (0, 180, 0), 2)\n",
    "    cv2.line(dmy, (0, 80),(256,80),(100, 255, 255))\n",
    "    cv2.imwrite(pathIn+str(i)+'.png',dmy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text recognition\n",
    "import cv2\n",
    "import pytesseract\n",
    "# read image\n",
    "im = cv2.imread('./test.jpg')\n",
    "# configurations\n",
    "config = ('-l eng --oem 1 --psm 3')\n",
    "# pytessercat\n",
    "text = pytesseract.image_to_string(im, config=config)\n",
    "# print text\n",
    "#for word in text:\n",
    "   # if word != ():\n",
    "       # print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "video = './ball tracking/28.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "cnt=0\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print(\"There is an error in reading the file.\")\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        \n",
    "        roi = frame[:800,:]\n",
    "        thresh=600\n",
    "        end = roi.shape[1] - thresh\n",
    "        roi = roi[:,thresh:end]\n",
    "        \n",
    "        cv2.imshow('image', roi)\n",
    "        \n",
    "        #press q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        cv2.imwrite('/frames'+str(cnt)+'.png',roi)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "#listing down all the file names\n",
    "frames = os.listdir('frames/')\n",
    "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "#reading frames\n",
    "images=[]\n",
    "for i in frames:\n",
    "    img = cv2.imread('frames/'+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img,(25,25),0)\n",
    "    images.append(img)\n",
    "\n",
    "images=np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd4b02f8fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonzero=[]\n",
    "for i in range((len(images)-1)):\n",
    "    \n",
    "    mask = cv2.absdiff(images[i],images[i+1])\n",
    "    _ , mask = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)\n",
    "    num = np.count_nonzero((mask.ravel()))\n",
    "    nonzero.append(num)\n",
    "    \n",
    "    \n",
    "x = np.arange(0,len(images)-1)\n",
    "y = nonzero\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d2bacd54490f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10e3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mscene_change_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "threshold = 15 * 10e3\n",
    "for i in range(len(images)-1):\n",
    "    if(nonzero[i]>threshold): \n",
    "        scene_change_idx = i\n",
    "        break\n",
    "        \n",
    "frames = frames[:(scene_change_idx+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
